# -*- coding: utf-8 -*-
"""California Housing/Functional API ile model kurma

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19_N-EIJSMdkWXe-RpYX9gOxOItwmeGiR
"""

from sklearn.datasets import fetch_california_housing
housing=fetch_california_housing()
print(housing.DESCR)

from sklearn.model_selection import train_test_split
X_train , X_test , y_train , y_test = train_test_split(housing.data , housing.target , random_state=42)

import tensorflow as tf
tf.random.set_seed(42)

normalization_layer = tf.keras.layers.Normalization() #bu katmanı kullandığımız için Flatten katmanını kullanmamıza gerek yok.

#gizli katmanlar
hidden_layer_1 = tf.keras.layers.Dense(30 , activation="relu")
hidden_layer_2 = tf.keras.layers.Dense(30,activation= "relu")

#birleştirme katmanı
concat_layer = tf.keras.layers.Concatenate()

output_layer = tf.keras.layers.Dense(1) #problemimiz regresyon olduğu için yani sadece bir sayısal değer tahmini edeceğimiz için çıktı katmanına 1
                                        #nöron yazalım.

#girdi değişkeni
input_ = tf.keras.layers.Input(shape=X_train.shape[1:])  #özniteliğin sayısını verecek

#normalizasyon katmanı
normalized = normalization_layer(input_) #bu katmandan çıkan veriler gizli katmana gidecek

#gizli katman
hidden1 = hidden_layer_1(normalized)
hidden2 = hidden_layer_2(hidden1)

#gizli ve ikinci gizli katmanın çıktısını birleştirelim
concat = concat_layer([normalized , hidden2])

#verilerin çıktı katmanından çıkmasını sağlayalım
output = output_layer(concat)

#keras modelini kuralım.
model = tf.keras.Model(inputs= [input_] , outputs= [output])

model.summary()

#modelimizi compile edelim
optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)
model.compile(
    loss="mse",
    optimizer=optimizer,
    metrics=["RootMeanSquaredError"]
)

#modelimizi eğitelim, eğitmeden önce eğitim verilerini normalleştirmek için adapt metodunu kullanalım.
normalization_layer.adapt(X_train)

history = model.fit(
    X_train, y_train, validation_split = 0.2 , epochs=20
)

#model değerlendirme
mse_test = model.evaluate(X_test , y_test)

X_new = X_test[:3]
import pandas as pd
pd.DataFrame(X_new)

#tahmin edelim
y_pred = model.predict(X_new)
pd.DataFrame(y_pred)

pd.DataFrame(y_test[:3])

#BİRDEN FAZLA GİRDİ İÇİN FUNCTİONAL API

#girdi katmanları
input_wide = tf.keras.layers.Input(shape=[5])
input_deep = tf.keras.layers.Input(shape=[6])

#normalleştirme katmanı
norm_wide_output = norm_layer_wide(input_wide)
norm_deep_output = norm_layer_deep(input_deep)

#gizli katmanlar
hidden1 = tf.keras.layers.Dense(30 , activation="relu")(norm_deep_output)
hidden2 = tf.keras.layers.Dense(30 , activation="relu")(hidden1)

#gizli katman ve normalization katmanını birleştirelim
concat = tf.keras.layers.Concatenate()([norm_wide_output , hidden2])

#çıktı katmanı
output = tf.keras.layers.Dense(1)(concat)

#modelimizi olusturalım
model = tf.keras.Model(inputs=[input_wide , input_deep] , outputs=[output])

#compile edelim
optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)
model.compile(
    loss="mse",
    optimizer=optimizer,
    metrics=["RootMeanSquaredError"]
)

#eğitim veri setimizi oluşturalım
X_train_wide , X_train_deep = X_train[: , :5] , X_train[: , 2:]
X_test_wide , X_test_deep = X_test[: , :5] , X_test[: , 2:]

norm_layer_wide.adapt(X_train_wide)
norm_layer_deep.adapt(X_train_deep)

history = model.fit((X_train_wide , X_train_deep) , y_train , epochs=20 , validation_split=0.1)

#model değerlendirme
mse_test = model.evaluate((X_test_wide , X_test_deep) , y_test)

#tahmin
X_new_wide = X_test_wide[:3]
X_new_deep = X_test_deep[:3]
y_pred = model.predict((X_new_wide , X_new_deep))
pd.DataFrame(y_pred)

#ÇOKLU ÇIKTILAR İÇİN FUNCTİONAL API

#girdi katmanları
input_wide = tf.keras.layers.Input(shape=[5])
input_deep = tf.keras.layers.Input(shape=[6])
#normalleştirme katmanı
norm_wide_output = norm_layer_wide(input_wide)
norm_deep_output = norm_layer_deep(input_deep)
#gizli katmanlar
hidden1 = tf.keras.layers.Dense(30 , activation="relu")(norm_deep_output)
hidden2 = tf.keras.layers.Dense(30 , activation="relu")(hidden1)
#birleştirme katmanı for aux_model
concat_aux = tf.keras.layers.Concatenate()([norm_wide_output , hidden2])
#çıktı katmanları for aux_model
output = tf.keras.layers.Dense(1)(concat_aux)
aux_output = tf.keras.layers.Dense(1)(hidden2)
#modelimizi olusturalım
model = tf.keras.Model(inputs=[input_wide , input_deep] , outputs=[output])
aux_model = tf.keras.Model(inputs=[input_wide , input_deep] , outputs=[output , aux_output])

#compile edelim
optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)
aux_model.compile(
    loss=("mse","mse"),
    loss_weights=(0.9 , 0.1),
    optimizer=optimizer,
    metrics=["RootMeanSquaredError", "RootMeanSquaredError"]
)

norm_layer_wide.adapt(X_train_wide)
norm_layer_deep.adapt(X_train_deep)

#eğitim
history = aux_model.fit((X_train_wide , X_train_deep) , (y_train , y_train) , epochs=20 , validation_split=0.2)

#tahmin
y_pred_main , y_pred_aux = aux_model.predict((X_new_wide , X_new_deep))

y_pred_main

y_pred_aux









